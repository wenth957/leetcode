{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "张量表示一个数值组成的数组，有很多维度"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "x = torch.arange(12)\r\n",
    "x"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "x.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "x.numel()\r\n",
    "# number of element"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "x.reshape(3,4)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "torch.zeros((2,3,4))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "torch.ones((2,3,4))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "torch.tensor([[2,1,4,3],[2,3,1,5],[1,2,3,4]])\r\n",
    "# 嵌套数组"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[2, 1, 4, 3],\n",
       "        [2, 3, 1, 5],\n",
       "        [1, 2, 3, 4]])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "x = torch.tensor([1.0,2,4,8])\r\n",
    "y = torch.tensor([2,2,2,2])\r\n",
    "x+y,x-y,x*y,x/y,x**y\r\n",
    "# 按元素运算"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([ 3.,  4.,  6., 10.]),\n",
       " tensor([-1.,  0.,  2.,  6.]),\n",
       " tensor([ 2.,  4.,  8., 16.]),\n",
       " tensor([0.5000, 1.0000, 2.0000, 4.0000]),\n",
       " tensor([ 1.,  4., 16., 64.]))"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "x = torch.arange(12,dtype=torch.float32).reshape((3,4))\r\n",
    "y = torch.tensor([[2.0,1,4,3],[1,2,3,4],[4,3,2,1]])\r\n",
    "torch.cat((x,y),dim=0),torch.cat((x,y),dim=1)\r\n",
    "# 按行拼接，按列拼接\r\n",
    "# reshape在原来基础上操作"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [ 2.,  1.,  4.,  3.],\n",
       "         [ 1.,  2.,  3.,  4.],\n",
       "         [ 4.,  3.,  2.,  1.]]),\n",
       " tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\n",
       "         [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# 逻辑运算 ：元素\r\n",
    "x==y"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[False,  True, False,  True],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# 求和\r\n",
    "x.sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(66.)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# 广播机制\r\n",
    "a = torch.arange(3).reshape((3,1))\r\n",
    "b = torch.arange(2).reshape((1,2))\r\n",
    "a,b"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[0],\n",
       "         [1],\n",
       "         [2]]),\n",
       " tensor([[0, 1]]))"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "a+b #a会复制成两列，b会复制成三行"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [1, 2],\n",
       "        [2, 3]])"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "x[-1],x[1:3]\r\n",
    "# 行"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([ 8.,  9., 10., 11.]),\n",
       " tensor([[ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.]]))"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "x[1,2] = 9\r\n",
    "x #写入"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  9.,  7.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "x[0:2,:] =12\r\n",
    "x"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[12., 12., 12., 12.],\n",
       "        [12., 12., 12., 12.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# 内存问题\r\n",
    "before = id(y)\r\n",
    "y =y +x\r\n",
    "id(y) ==before  # id理解为指针\r\n",
    "# 最好不要不断赋值"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# 原地操作\r\n",
    "z = torch.zeros_like(y)\r\n",
    "print('id(z):',id(z))\r\n",
    "z[:] = x+y  # 元素改写，不是赋值\r\n",
    "print('id(z):',id(z))\r\n",
    "before = id(x)\r\n",
    "x+=y  # 没用重复使用x也可\r\n",
    "id(x) == before"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "id(z): 1733316021344\n",
      "id(z): 1733316021344\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# 转换为numpy\r\n",
    "A= x.numpy()\r\n",
    "B = torch.tensor(A)\r\n",
    "type(A),type(B)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(numpy.ndarray, torch.Tensor)"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# 标量\r\n",
    "a = torch.tensor([1.0])\r\n",
    "a,a.item(),float(a),int(a)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([1.]), 1.0, 1.0, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "import os\r\n",
    "\r\n",
    "os.makedirs(os.path.join('../','data'),exist_ok=True)\r\n",
    "data_file = os.path.join('../','data','house_tiny.csv')\r\n",
    "with open(data_file,'w') as f:\r\n",
    "    f.write(\"NumRooms, Alley , Price\\n\") #列名\r\n",
    "    f.write(\"NA,Pave,127500\\n\")\r\n",
    "    f.write(\"2,NA,106000\\n\")\r\n",
    "    f.write(\"4,NA,178100\\n\")\r\n",
    "    f.write(\"NA,NA,140000\\n\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "import pandas as pd\r\n",
    "\r\n",
    "data = pd.read_csv(data_file)\r\n",
    "data"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   NumRooms  Alley    Price\n",
       "0       NaN    Pave  127500\n",
       "1       2.0     NaN  106000\n",
       "2       4.0     NaN  178100\n",
       "3       NaN     NaN  140000"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NumRooms</th>\n",
       "      <th>Alley</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Pave</td>\n",
       "      <td>127500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>178100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# 处理缺失数据\r\n",
    "# iloc index of location\r\n",
    "inputs,outputs = data.iloc[:,0:2],data.iloc[:,2]\r\n",
    "inputs = inputs.fillna(inputs.mean()) #数值型\r\n",
    "inputs = pd.get_dummies(inputs,dummy_na=True) # 将NA 看作一类\r\n",
    "inputs"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   NumRooms   Alley _Pave   Alley _nan\n",
       "0       3.0             1            0\n",
       "1       2.0             0            1\n",
       "2       4.0             0            1\n",
       "3       3.0             0            1"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NumRooms</th>\n",
       "      <th>Alley _Pave</th>\n",
       "      <th>Alley _nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "# 转换成张量形式\r\n",
    "import torch\r\n",
    "\r\n",
    "X,y  = torch.tensor(inputs.values),torch.tensor(outputs.values)\r\n",
    "X,y"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[3., 1., 0.],\n",
       "         [2., 0., 1.],\n",
       "         [4., 0., 1.],\n",
       "         [3., 0., 1.]], dtype=torch.float64),\n",
       " tensor([127500, 106000, 178100, 140000]))"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "线性代数"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "A = torch.arange(20).reshape((4,5))\r\n",
    "A"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8,  9],\n",
       "        [10, 11, 12, 13, 14],\n",
       "        [15, 16, 17, 18, 19]])"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "A.T"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0,  5, 10, 15],\n",
       "        [ 1,  6, 11, 16],\n",
       "        [ 2,  7, 12, 17],\n",
       "        [ 3,  8, 13, 18],\n",
       "        [ 4,  9, 14, 19]])"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "B = torch.tensor([[1,2,3],[2,0,4],[3,4,5]])\r\n",
    "B"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [2, 0, 4],\n",
       "        [3, 4, 5]])"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "B.T ==B #判断对称矩阵"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "# 创建任意轴的数据结构 :从外往里排\r\n",
    "C= torch.arange(24).reshape((2,3,4))\r\n",
    "C"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]]])"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "# 相同形状计算\r\n",
    "A = torch.arange(20,dtype=torch.float32).reshape((4,5))\r\n",
    "B = A.clone() # 分配新内存，A的副本\r\n",
    "A+B,B"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  2.,  4.,  6.,  8.],\n",
       "         [10., 12., 14., 16., 18.],\n",
       "         [20., 22., 24., 26., 28.],\n",
       "         [30., 32., 34., 36., 38.]]),\n",
       " tensor([[ 0.,  1.,  2.,  3.,  4.],\n",
       "         [ 5.,  6.,  7.,  8.,  9.],\n",
       "         [10., 11., 12., 13., 14.],\n",
       "         [15., 16., 17., 18., 19.]]))"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "A*B #哈德马积"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[  0.,   1.,   4.,   9.,  16.],\n",
       "        [ 25.,  36.,  49.,  64.,  81.],\n",
       "        [100., 121., 144., 169., 196.],\n",
       "        [225., 256., 289., 324., 361.]])"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "a = 2\r\n",
    "X = torch.arange(20,dtype=torch.float32).reshape((4,5))\r\n",
    "X+a,(a*X).shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[ 2.,  3.,  4.,  5.,  6.],\n",
       "         [ 7.,  8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15., 16.],\n",
       "         [17., 18., 19., 20., 21.]]),\n",
       " torch.Size([4, 5]))"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "# 计算元素和\r\n",
    "X.sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(190.)"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "# 任意形状求和\r\n",
    "X = torch.arange(20*2,dtype=torch.float32).reshape((2,4,5))\r\n",
    "sum_x= X.sum()\r\n",
    "sum_x,sum_x.shape #标量"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor(780.), torch.Size([]))"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "sum_x0 = X.sum(axis=0)\r\n",
    "sum_x0,sum_x0.shape  #第一轴没了"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[20., 22., 24., 26., 28.],\n",
       "         [30., 32., 34., 36., 38.],\n",
       "         [40., 42., 44., 46., 48.],\n",
       "         [50., 52., 54., 56., 58.]]),\n",
       " torch.Size([4, 5]))"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "sum_x1 = X.sum(axis=1)\r\n",
    "sum_x1,sum_x1.shape # 中间轴没了"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[ 30.,  34.,  38.,  42.,  46.],\n",
       "         [110., 114., 118., 122., 126.]]),\n",
       " torch.Size([2, 5]))"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "sum_x2 = X.sum(axis=2)\r\n",
    "sum_x2,sum_x2.shape #第三个轴没了"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[ 10.,  35.,  60.,  85.],\n",
       "         [110., 135., 160., 185.]]),\n",
       " torch.Size([2, 4]))"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "sum_x01 = X.sum(axis=[0,1])\r\n",
    "sum_x01,sum_x01.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([140., 148., 156., 164., 172.]), torch.Size([5]))"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "X.mean(),X.sum()/X.numel()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor(19.5000), tensor(19.5000))"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "X.mean(axis=0),X.sum(axis=0)/X.shape[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[10., 11., 12., 13., 14.],\n",
       "         [15., 16., 17., 18., 19.],\n",
       "         [20., 21., 22., 23., 24.],\n",
       "         [25., 26., 27., 28., 29.]]),\n",
       " tensor([[10., 11., 12., 13., 14.],\n",
       "         [15., 16., 17., 18., 19.],\n",
       "         [20., 21., 22., 23., 24.],\n",
       "         [25., 26., 27., 28., 29.]]))"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "# 如果运算时不想降维(1d 2d 3d这种) 最后求和轴变为1而不是0\r\n",
    "sum_X = X.sum(axis=1,keepdims=True)\r\n",
    "sum_X\r\n",
    "# 广播机制维度必须相同"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[ 30.,  34.,  38.,  42.,  46.]],\n",
       "\n",
       "        [[110., 114., 118., 122., 126.]]])"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "X/sum_X"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0294, 0.0526, 0.0714, 0.0870],\n",
       "         [0.1667, 0.1765, 0.1842, 0.1905, 0.1957],\n",
       "         [0.3333, 0.3235, 0.3158, 0.3095, 0.3043],\n",
       "         [0.5000, 0.4706, 0.4474, 0.4286, 0.4130]],\n",
       "\n",
       "        [[0.1818, 0.1842, 0.1864, 0.1885, 0.1905],\n",
       "         [0.2273, 0.2281, 0.2288, 0.2295, 0.2302],\n",
       "         [0.2727, 0.2719, 0.2712, 0.2705, 0.2698],\n",
       "         [0.3182, 0.3158, 0.3136, 0.3115, 0.3095]]])"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "X"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  1.,  2.,  3.,  4.],\n",
       "         [ 5.,  6.,  7.,  8.,  9.],\n",
       "         [10., 11., 12., 13., 14.],\n",
       "         [15., 16., 17., 18., 19.]],\n",
       "\n",
       "        [[20., 21., 22., 23., 24.],\n",
       "         [25., 26., 27., 28., 29.],\n",
       "         [30., 31., 32., 33., 34.],\n",
       "         [35., 36., 37., 38., 39.]]])"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "X.cumsum(axis=1)\r\n",
    "# 累计和"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[  0.,   1.,   2.,   3.,   4.],\n",
       "         [  5.,   7.,   9.,  11.,  13.],\n",
       "         [ 15.,  18.,  21.,  24.,  27.],\n",
       "         [ 30.,  34.,  38.,  42.,  46.]],\n",
       "\n",
       "        [[ 20.,  21.,  22.,  23.,  24.],\n",
       "         [ 45.,  47.,  49.,  51.,  53.],\n",
       "         [ 75.,  78.,  81.,  84.,  87.],\n",
       "         [110., 114., 118., 122., 126.]]])"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "# 点积 按元素乘再求和\r\n",
    "x = torch.arange(4,dtype=torch.float32)\r\n",
    "y= torch.ones(4,dtype=torch.float32)\r\n",
    "x,y,torch.dot(x,y)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.]), tensor([1., 1., 1., 1.]), tensor(6.))"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "# 矩阵向量乘法 matric vector\r\n",
    "A.T.shape,x.shape,torch.mv(A.T,x)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([5, 4]), torch.Size([4]), tensor([70., 76., 82., 88., 94.]))"
      ]
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "B=torch.ones((4,3))\r\n",
    "A.T,torch.mm(A.T,B)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  5., 10., 15.],\n",
       "         [ 1.,  6., 11., 16.],\n",
       "         [ 2.,  7., 12., 17.],\n",
       "         [ 3.,  8., 13., 18.],\n",
       "         [ 4.,  9., 14., 19.]]),\n",
       " tensor([[30., 30., 30.],\n",
       "         [34., 34., 34.],\n",
       "         [38., 38., 38.],\n",
       "         [42., 42., 42.],\n",
       "         [46., 46., 46.]]))"
      ]
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "# L2范数\r\n",
    "u = torch.tensor([3.0,-4.0])\r\n",
    "u.norm()\r\n",
    "# 平方和开根号"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "# L1范数\r\n",
    "torch.abs(u).sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "# 矩阵F范数\r\n",
    "torch.norm(torch.ones((4,9)))\r\n",
    "# 平方和开根号"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 梯度：分子布局符号 也可以规定分母布局\r\n",
    "- 标量对列向量x的导数是行向量\r\n",
    "- 梯度和等高线正交，变化最大的方向\r\n",
    "- 列向量对标量的导数是列向量\r\n",
    "- 列向量对列向量是矩阵\r\n",
    "- 矩阵对标量不变\r\n",
    "- 矩阵对向量求导，接到后面，分母总要转置"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 自动求导：区别于符号求导和数值求导\r\n",
    "- 计算图：链式法则，正向积累，反向传播\r\n",
    "- 先正向存储结果，然后反向计算，内存复杂度较高\r\n",
    "- 关键是计算图的构造\r\n",
    "  - 显示构造：定义好公式代入值\r\n",
    "  - 隐式构造：记住数值，直接计算"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "# 存储梯度\r\n",
    "x = torch.arange(4.0,requires_grad=True)\r\n",
    "y = 2* torch.dot(x,x)\r\n",
    "y.backward()\r\n",
    "x.grad"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([ 0.,  4.,  8., 12.])"
      ]
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "x.grad == 4*x"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "# torch会积累梯度，所以清楚之前的值\r\n",
    "x.grad.zero_()\r\n",
    "x.grad"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.])"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "y = x.sum()\r\n",
    "y.backward()\r\n",
    "x.grad"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.])"
      ]
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "source": [
    "# 深度学习中很少用向量来求导\r\n",
    "x.grad.zero_()\r\n",
    "y = x*x\r\n",
    "y.sum().backward()\r\n",
    "x.grad ==x*2"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "# 某些计算移到计算图以外\r\n",
    "x.grad.zero_()\r\n",
    "u = y.detach()   #对系统来讲u不再是关于x的函数\r\n",
    "z = u*x\r\n",
    "z.sum().backward()\r\n",
    "x.grad == u      #可以将某些参数固定住"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "source": [
    "# 复杂的控制系统也可以解决\r\n",
    "def f(a):\r\n",
    "    b = a*2\r\n",
    "    while b.norm()< 1000:\r\n",
    "        b = b*2\r\n",
    "    if b.sum()>0:\r\n",
    "        c =b\r\n",
    "    else:\r\n",
    "        c = 100*b\r\n",
    "    return c\r\n",
    "\r\n",
    "a = torch.randn(size=(),requires_grad=True)\r\n",
    "d = f(a)\r\n",
    "d.backward()\r\n",
    "a.grad == d/a"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "metadata": {},
     "execution_count": 108
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.7 64-bit"
  },
  "interpreter": {
   "hash": "4eaf1be304415beee96765ae99c3f893cc8312c7f1196698e6029668e9aeb3e5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}