{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 感知机\r\n",
    "- 线性组合\r\n",
    "- 激活函数：回归：线性回归输出实数；分类：softmax输出概率\r\n",
    "- 训练：分类错误则更新w，b，直到所有分类正确\r\n",
    "- 可以用梯度下降:损失函数为：max(0,-y*wTx)\r\n",
    "- 收敛定理：一定会停止 ，类似支持向量机存在一个余量，可以分隔开\r\n",
    "- 不能解决异或问题"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 多层感知机\r\n",
    "- 异或门解决：\r\n",
    "    - 学习第一根直线，与非门，分开两部分  全1 非全1  \r\n",
    "    - 学习第二根直线，或门 分开两部分：有1 无1\r\n",
    "    - 两步分结果传入与门即可得到正确的分类\r\n",
    "    - 方法不唯一\r\n",
    "- 多层感知机\r\n",
    "   - 输入层固定\r\n",
    "   - 隐藏层个数是超参数\r\n",
    "   - 激活函数一定是非线性的\r\n",
    "- 激活函数\r\n",
    "  - sigmoid (0,1)\r\n",
    "  - tanh (-1,1)\r\n",
    "  - ReLU : max(x,0)    计算较快\r\n",
    "- 多类分类\r\n",
    "  - softmax：加一层隐藏层，然后输出层做softmax即可\r\n",
    "- 隐藏层设置\r\n",
    "  - 第一层可以扩展\r\n",
    "  - 其他层一般慢慢压缩"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "from torch import nn\r\n",
    "from d2l import torch as d2l\r\n",
    "\r\n",
    "batch_size =256\r\n",
    "train_iter,test_iter = d2l.load_data_fashion_mnist(batch_size)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "num_inputs,num_outputs,num_hidden = 784,10,256\r\n",
    "\r\n",
    "W1 = nn.Parameter(torch.randn(num_inputs,num_hidden,requires_grad=True))\r\n",
    "b1 = nn.Parameter(torch.zeros(num_hidden,requires_grad=True))\r\n",
    "W2 = nn.Parameter(torch.randn(num_hidden,num_outputs,requires_grad=True))\r\n",
    "b2 = nn.Parameter(torch.zeros(num_outputs,requires_grad=True))\r\n",
    "params = [W1,b1,W2,b2]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# 激活函数\r\n",
    "def ReLU(X):\r\n",
    "    a = torch.zeros_like(X) # 0\r\n",
    "    return torch.max(X,a)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def net(X):\r\n",
    "    X = X.reshape((-1,num_inputs))\r\n",
    "    H = ReLU(X@W1+b1)\r\n",
    "    return (H@W2+b2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "loss = nn.CrossEntropyLoss()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "num_epochs,lr = 10,0.1\r\n",
    "updater = torch.optim.SGD(params,lr=lr)\r\n",
    "d2l.train_ch3(net,train_iter,test_iter,loss,num_epochs,updater)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# 简洁实现\r\n",
    "net = nn.Sequential(\r\n",
    "    nn.Flatten(),nn.Linear(784,256),nn.ReLU(),nn.Linear(256,10)\r\n",
    ")\r\n",
    "\r\n",
    "def init_weights(m):\r\n",
    "    if type(m) == nn.Linear:\r\n",
    "        nn.init.normal_(m.weight,std=0.01)\r\n",
    "\r\n",
    "net.apply(init_weights)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (2): ReLU()\n",
       "  (3): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "batch_size,lr,num_epochs = 256,0.1,30\r\n",
    "loss = nn.CrossEntropyLoss()\r\n",
    "trainer = torch.optim.SGD(net.parameters(),lr=0.1)\r\n",
    "\r\n",
    "train_iter,test_iter = d2l.load_data_fashion_mnist(batch_size)\r\n",
    "d2l.train_ch3(net,train_iter,test_iter,loss,num_epochs,updater)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- SVM比多层感知机晚一点\r\n",
    "- SVM超参数少一点\r\n",
    "- SVM数学性强\r\n",
    "- 神经元过多容易过拟合，深度学习\r\n",
    "- 选择层数和神经元：从一层开始，增加隐藏层，从简单到复杂\r\n",
    "- 稳定性：泛化能力"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.7 64-bit"
  },
  "interpreter": {
   "hash": "4eaf1be304415beee96765ae99c3f893cc8312c7f1196698e6029668e9aeb3e5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}